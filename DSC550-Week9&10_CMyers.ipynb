{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "\n",
    "# #1\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# #2\n",
    "import keras\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "\n",
    "# #3\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sports</td>\n",
       "      <td>Barely better than Gabbert? He was significant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sports</td>\n",
       "      <td>Fuck the ducks and the Angels! But welcome to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sports</td>\n",
       "      <td>Should have drafted more WRs.\\n\\n- Matt Millen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sports</td>\n",
       "      <td>[Done](https://i.imgur.com/2YZ90pm.jpg)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sports</td>\n",
       "      <td>No!! NOO!!!!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cat                                                txt\n",
       "0  sports  Barely better than Gabbert? He was significant...\n",
       "1  sports  Fuck the ducks and the Angels! But welcome to ...\n",
       "2  sports  Should have drafted more WRs.\\n\\n- Matt Millen...\n",
       "3  sports            [Done](https://i.imgur.com/2YZ90pm.jpg)\n",
       "4  sports                                      No!! NOO!!!!!"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the jsonlines file and then fill a dataframe with the jsonlines data.\n",
    "# Due to the computation time down stream, only 50k rows will be used.\n",
    "df = pd.read_json(\"categorized-comments.jsonl\", lines = True, nrows = 50000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that cleans (lowercase transformation, removal of special chars, etc.) our txt field row by \n",
    "# row using three regular expressions\n",
    "\n",
    "def clean_data(data):\n",
    "    data=data.lower()\n",
    "    data=re.sub('&lt;/?.*?&gt;',' &lt;&gt', data)\n",
    "    data=re.sub('\\\\d|\\\\W+|_',' ', data)\n",
    "    data=re.sub('[^a-zA-Z]',\" \", data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our list of english stopwords\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sports</td>\n",
       "      <td>barely better than gabbert he was significantl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sports</td>\n",
       "      <td>fuck the ducks and the angels but welcome to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sports</td>\n",
       "      <td>should have drafted more wrs matt millen probably</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sports</td>\n",
       "      <td>done https i imgur com  yz  pm jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sports</td>\n",
       "      <td>no noo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cat                                                txt\n",
       "0  sports  barely better than gabbert he was significantl...\n",
       "1  sports  fuck the ducks and the angels but welcome to a...\n",
       "2  sports  should have drafted more wrs matt millen probably\n",
       "3  sports                done https i imgur com  yz  pm jpg \n",
       "4  sports                                            no noo "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean our txt field using our previously defined function\n",
    "df['txt'] = df['txt'].apply(lambda x:clean_data(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#1 \\n\\nFit a neural network classifier using sklearn and report the model accuracy, \\npercision, f1 score, and the confusion matrix.\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#1 \n",
    "\n",
    "Fit a neural network classifier using sklearn and report the model accuracy, \n",
    "percision, f1 score, and the confusion matrix.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a count vectorizer while ignoring the stopwords\n",
    "cv = CountVectorizer(stop_words = stopwords)\n",
    "\n",
    "# Fit our count vectorizer with our txt field and save it as our input variable for our neural network classifier\n",
    "X = cv.fit_transform(df['txt'])\n",
    "Y = df['cat']\n",
    "\n",
    "# Split our data set for training and testing purposes\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our multi-layer perceptron classifier with 100 hidden layers\n",
    "mlp = MLPClassifier(hidden_layer_sizes=10, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.53453802\n",
      "Iteration 2, loss = 0.34932650\n",
      "Iteration 3, loss = 0.27017948\n",
      "Iteration 4, loss = 0.22698703\n",
      "Iteration 5, loss = 0.19885163\n",
      "Iteration 6, loss = 0.17862699\n",
      "Iteration 7, loss = 0.16343034\n",
      "Iteration 8, loss = 0.15130744\n",
      "Iteration 9, loss = 0.14163894\n",
      "Iteration 10, loss = 0.13360532\n",
      "Iteration 11, loss = 0.12679634\n",
      "Iteration 12, loss = 0.12109576\n",
      "Iteration 13, loss = 0.11625545\n",
      "Iteration 14, loss = 0.11216470\n",
      "Iteration 15, loss = 0.10847100\n",
      "Iteration 16, loss = 0.10520088\n",
      "Iteration 17, loss = 0.10243520\n",
      "Iteration 18, loss = 0.09997752\n",
      "Iteration 19, loss = 0.09778724\n",
      "Iteration 20, loss = 0.09579209\n",
      "Iteration 21, loss = 0.09406599\n",
      "Iteration 22, loss = 0.09240689\n",
      "Iteration 23, loss = 0.09100975\n",
      "Iteration 24, loss = 0.08969649\n",
      "Iteration 25, loss = 0.08850003\n",
      "Iteration 26, loss = 0.08746959\n",
      "Iteration 27, loss = 0.08647156\n",
      "Iteration 28, loss = 0.08554601\n",
      "Iteration 29, loss = 0.08474705\n",
      "Iteration 30, loss = 0.08390563\n",
      "Iteration 31, loss = 0.08328080\n",
      "Iteration 32, loss = 0.08249786\n",
      "Iteration 33, loss = 0.08197422\n",
      "Iteration 34, loss = 0.08142413\n",
      "Iteration 35, loss = 0.08085158\n",
      "Iteration 36, loss = 0.08024112\n",
      "Iteration 37, loss = 0.07985897\n",
      "Iteration 38, loss = 0.07944127\n",
      "Iteration 39, loss = 0.07901160\n",
      "Iteration 40, loss = 0.07859042\n",
      "Iteration 41, loss = 0.07816571\n",
      "Iteration 42, loss = 0.07788275\n",
      "Iteration 43, loss = 0.07760080\n",
      "Iteration 44, loss = 0.07727465\n",
      "Iteration 45, loss = 0.07709431\n",
      "Iteration 46, loss = 0.07670473\n",
      "Iteration 47, loss = 0.07663165\n",
      "Iteration 48, loss = 0.07618992\n",
      "Iteration 49, loss = 0.07620249\n",
      "Iteration 50, loss = 0.07602534\n",
      "Iteration 51, loss = 0.07572486\n",
      "Iteration 52, loss = 0.07561645\n",
      "Iteration 53, loss = 0.07532800\n",
      "Iteration 54, loss = 0.07515874\n",
      "Iteration 55, loss = 0.07497467\n",
      "Iteration 56, loss = 0.07485069\n",
      "Iteration 57, loss = 0.07486001\n",
      "Iteration 58, loss = 0.07463717\n",
      "Iteration 59, loss = 0.07441888\n",
      "Iteration 60, loss = 0.07429749\n",
      "Iteration 61, loss = 0.07417056\n",
      "Iteration 62, loss = 0.07412367\n",
      "Iteration 63, loss = 0.07406440\n",
      "Iteration 64, loss = 0.07393885\n",
      "Iteration 65, loss = 0.07379124\n",
      "Iteration 66, loss = 0.07362289\n",
      "Iteration 67, loss = 0.07361404\n",
      "Iteration 68, loss = 0.07340330\n",
      "Iteration 69, loss = 0.07350502\n",
      "Iteration 70, loss = 0.07346487\n",
      "Iteration 71, loss = 0.07325885\n",
      "Iteration 72, loss = 0.07321001\n",
      "Iteration 73, loss = 0.07312918\n",
      "Iteration 74, loss = 0.07309423\n",
      "Iteration 75, loss = 0.07318004\n",
      "Iteration 76, loss = 0.07298415\n",
      "Iteration 77, loss = 0.07288998\n",
      "Iteration 78, loss = 0.07288558\n",
      "Iteration 79, loss = 0.07289969\n",
      "Iteration 80, loss = 0.07279049\n",
      "Iteration 81, loss = 0.07269956\n",
      "Iteration 82, loss = 0.07279834\n",
      "Iteration 83, loss = 0.07252148\n",
      "Iteration 84, loss = 0.07254489\n",
      "Iteration 85, loss = 0.07252560\n",
      "Iteration 86, loss = 0.07250165\n",
      "Iteration 87, loss = 0.07247569\n",
      "Iteration 88, loss = 0.07248463\n",
      "Iteration 89, loss = 0.07250403\n",
      "Iteration 90, loss = 0.07243446\n",
      "Iteration 91, loss = 0.07229137\n",
      "Iteration 92, loss = 0.07221506\n",
      "Iteration 93, loss = 0.07227907\n",
      "Iteration 94, loss = 0.07230853\n",
      "Iteration 95, loss = 0.07228862\n",
      "Iteration 96, loss = 0.07220635\n",
      "Iteration 97, loss = 0.07220511\n",
      "Iteration 98, loss = 0.07221857\n",
      "Iteration 99, loss = 0.07210935\n",
      "Iteration 100, loss = 0.07199235\n",
      "Iteration 101, loss = 0.07194252\n",
      "Iteration 102, loss = 0.07201439\n",
      "Iteration 103, loss = 0.07201129\n",
      "Iteration 104, loss = 0.07196280\n",
      "Iteration 105, loss = 0.07190039\n",
      "Iteration 106, loss = 0.07199642\n",
      "Iteration 107, loss = 0.07192977\n",
      "Iteration 108, loss = 0.07204096\n",
      "Iteration 109, loss = 0.07212412\n",
      "Iteration 110, loss = 0.07170789\n",
      "Iteration 111, loss = 0.07198635\n",
      "Iteration 112, loss = 0.07192137\n",
      "Iteration 113, loss = 0.07176585\n",
      "Iteration 114, loss = 0.07166467\n",
      "Iteration 115, loss = 0.07177943\n",
      "Iteration 116, loss = 0.07191150\n",
      "Iteration 117, loss = 0.07168755\n",
      "Iteration 118, loss = 0.07172983\n",
      "Iteration 119, loss = 0.07169809\n",
      "Iteration 120, loss = 0.07178140\n",
      "Iteration 121, loss = 0.07169563\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=10, verbose=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit our neural network classifier with our training data\n",
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of predictions using our testing data\n",
    "preds = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: \n",
      " 0.8378\n"
     ]
    }
   ],
   "source": [
    "print('Model Accuracy: \\n', accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[8691 1433]\n",
      " [1811 8065]]\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, preds)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "science_and_technology       0.83      0.86      0.84     10124\n",
      "                sports       0.85      0.82      0.83      9876\n",
      "\n",
      "              accuracy                           0.84     20000\n",
      "             macro avg       0.84      0.84      0.84     20000\n",
      "          weighted avg       0.84      0.84      0.84     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report: \\n', classification_report(y_test, preds)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the memory of all large variables\n",
    "del df\n",
    "del X_train\n",
    "del X_test\n",
    "del y_train\n",
    "del y_test\n",
    "del preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#2\\n\\nFit a neural network classifier using keras and report the model accuracy, \\npercision, f1 score, and the confusion matrix.\\n\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#2\n",
    "\n",
    "Fit a neural network classifier using keras and report the model accuracy, \n",
    "percision, f1 score, and the confusion matrix.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sports</td>\n",
       "      <td>Barely better than Gabbert? He was significant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sports</td>\n",
       "      <td>Fuck the ducks and the Angels! But welcome to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sports</td>\n",
       "      <td>Should have drafted more WRs.\\n\\n- Matt Millen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sports</td>\n",
       "      <td>[Done](https://i.imgur.com/2YZ90pm.jpg)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sports</td>\n",
       "      <td>No!! NOO!!!!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cat                                                txt\n",
       "0  sports  Barely better than Gabbert? He was significant...\n",
       "1  sports  Fuck the ducks and the Angels! But welcome to ...\n",
       "2  sports  Should have drafted more WRs.\\n\\n- Matt Millen...\n",
       "3  sports            [Done](https://i.imgur.com/2YZ90pm.jpg)\n",
       "4  sports                                      No!! NOO!!!!!"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the categorized comments into a dataframe\n",
    "\n",
    "df = pd.read_json(\"categorized-comments.jsonl\", lines = True, nrows = 100000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>science_and_technology</td>\n",
       "      <td>no it s not a thief can t use the phone after ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>science_and_technology</td>\n",
       "      <td>all the uk networks do as far as i know but   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>science_and_technology</td>\n",
       "      <td>am i the only one who hates read receipts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>science_and_technology</td>\n",
       "      <td>tab s  owner here same here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>science_and_technology</td>\n",
       "      <td>not talking about market cap talking about bus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      cat                                                txt\n",
       "0  science_and_technology  no it s not a thief can t use the phone after ...\n",
       "1  science_and_technology  all the uk networks do as far as i know but   ...\n",
       "2  science_and_technology         am i the only one who hates read receipts \n",
       "3  science_and_technology                       tab s  owner here same here \n",
       "4  science_and_technology  not talking about market cap talking about bus..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the sample size\n",
    "size = 1500\n",
    "\n",
    "# Define the replace argument in our lambda function\n",
    "replace = True\n",
    "\n",
    "# Define the lambda function that randomly chooses 1500 of each category for our resulting dataframe\n",
    "fn = lambda obj: obj.loc[np.random.choice(obj.index, size, replace),:]\n",
    "\n",
    "# Group each of our categories in a new dataset and apply our previously defined lambda function\n",
    "cat_df = df.groupby('cat', as_index=False).apply(fn)\n",
    "\n",
    "# Remove all punctuation, make all letters lowercase,and remove special characters\n",
    "cat_df['txt'] = cat_df['txt'].apply(lambda x:clean_data(x))\n",
    "\n",
    "# Reset the index of our cleaned dataframe\n",
    "cat_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "cat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat\n",
       "science_and_technology    1500\n",
       "sports                    1500\n",
       "video_games               1500\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that the categories have equal row counts\n",
    "cat_df.groupby([\"cat\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the LabelEncoder\n",
    "# The label encoder is a type of encoding that should only be used on the target values\n",
    "# This replaces our categorical data with numeric data that ranges from 0 to n - 1.\n",
    "enc = LabelEncoder()\n",
    "\n",
    "# Define our target variable\n",
    "cat = cat_df[\"cat\"]\n",
    "\n",
    "# Fit our encoder and return a new row of numeric data\n",
    "cat_df[\"cat\"] = enc.fit_transform(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat\n",
       "0    1500\n",
       "1    1500\n",
       "2    1500\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that the encoding worked as expected\n",
    "# We are expecting the same dataframe that we saw the previous time we ran this code, except that the categories are numeric\n",
    "cat_df.groupby([\"cat\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the max number of features our count vectorizer will use\n",
    "feat_count = 1500\n",
    "\n",
    "# Instantiate the count vectorizer, which we will in turn use to create a feature matrix\n",
    "cv = CountVectorizer(analyzer='word',\n",
    "                     stop_words=stopwords, \n",
    "                     max_features = feat_count,\n",
    "                     max_df = 0.5,\n",
    "                     min_df = 3)\n",
    "\n",
    "# Define a feature matrix based on our txt field\n",
    "X = cv.fit_transform(cat_df['txt'])\n",
    "\n",
    "# Define our target variable\n",
    "y = cat_df['cat']\n",
    "\n",
    "# Split our dataset for training and testing purposes using 40% of our data for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a sparse matrix to a sparse tensor so that the sequential classifier can accept it\n",
    "def convert_sparse_matrix_to_sparse_tensor(X):\n",
    "    # Create a coordinate representation of our scipy sparse matrix\n",
    "    coo = X.tocoo()\n",
    "    \n",
    "    # Define the indicies of the coordinate matrix and transpose the matrix\n",
    "    indices = np.mat([coo.row, coo.col]).transpose()\n",
    "    \n",
    "    # Return a sparse tensor\n",
    "    return tf.SparseTensor(indices, coo.data, coo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform our scipy sparse matrix to a sparse tensor and then reorder the indicies\n",
    "X_train = tf.sparse.reorder(convert_sparse_matrix_to_sparse_tensor(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the pandas series to a tensor\n",
    "y_train = tf.convert_to_tensor(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our sequential classifier\n",
    "classifier_seq = Sequential()\n",
    "\n",
    "# Add layers to our sequential classifier\n",
    "classifier_seq.add(Dense(units=500,activation=\"relu\",input_shape=(feat_count,)))\n",
    "classifier_seq.add(Dense(units=50, activation=\"relu\"))\n",
    "classifier_seq.add(Dense(units=4, activation=\"softmax\"))\n",
    "\n",
    "# Compile the sequential artificial neural network\n",
    "classifier_seq.compile(optimizer=\"rmsprop\", \n",
    "                       loss=\"sparse_categorical_crossentropy\", \n",
    "                       metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "14/14 [==============================] - 2s 18ms/step - loss: 1.2272 - accuracy: 0.4419\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.7389 - accuracy: 0.7637\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.5144 - accuracy: 0.8193\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.3950 - accuracy: 0.8577\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.3096 - accuracy: 0.8807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c328a46a90>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model using the training data and expose the progress of the fit with the verbose argument\n",
    "classifier_seq.fit(X_train, y_train, batch_size=200, epochs=5, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 500)               750500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                25050     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 204       \n",
      "=================================================================\n",
      "Total params: 775,754\n",
      "Trainable params: 775,754\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Observe a summary of the layers of our neural network\n",
    "classifier_seq.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform our scipy sparse matrix to a sparse tensor and then reorder the indicies\n",
    "X_test = tf.sparse.reorder(convert_sparse_matrix_to_sparse_tensor(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the pandas series to a tensor\n",
    "y_test = tf.convert_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 1s 3ms/step - loss: 0.6772 - accuracy: 0.7139\n",
      "Training Accuracy: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and define loss and accuracy\n",
    "loss, accuracy = classifier_seq.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Training Accuracy: \\n\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\myers\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# Define the target predictions based upon on the test set of our inputs\n",
    "y_pred = classifier_seq.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[422  66 125]\n",
      " [ 58 370 144]\n",
      " [ 45  77 493]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.69      0.74       613\n",
      "           1       0.72      0.65      0.68       572\n",
      "           2       0.65      0.80      0.72       615\n",
      "\n",
      "    accuracy                           0.71      1800\n",
      "   macro avg       0.72      0.71      0.71      1800\n",
      "weighted avg       0.72      0.71      0.71      1800\n",
      "\n",
      "Accuracy: \n",
      " 0.7138888888888889\n"
     ]
    }
   ],
   "source": [
    "# Print the metrics of our model\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report: \\n\", classification_report(y_test,y_pred))\n",
    "print(\"Accuracy: \\n\", accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the memory of our larger variables\n",
    "del df\n",
    "del X_train\n",
    "del X_test\n",
    "del y_train\n",
    "del y_test\n",
    "del y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#3\\n\\nClassify MSINT images using convolutional neural network and report the accuracy of the results.\\n\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#3\n",
    "\n",
    "Classify MSINT images using convolutional neural network and report the accuracy of the results.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the color channel value \n",
    "K.set_image_data_format(\"channels_last\")\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set image information\n",
    "channels = 1\n",
    "height = 28\n",
    "width = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and target from MNIST data\n",
    "(data_train, target_train), (data_test, target_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the training data image data into features\n",
    "data_train = data_train.reshape(data_train.shape[0], height, width, channels)\n",
    "\n",
    "# Reshape the training data image data into features\n",
    "data_test = data_test.reshape(data_test.shape[0], height, width, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale the pixel intensity to between 0 and 1\n",
    "features_train = data_train / 255\n",
    "features_test = data_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode target\n",
    "target_train = np_utils.to_categorical(target_train)\n",
    "target_test = np_utils.to_categorical(target_test)\n",
    "number_of_classes = target_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start sequential neural network \n",
    "network = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add convolutional layer with 64 filters, a 5x5 window, and ReLU activation function\n",
    "network.add(Conv2D(filters = 64,\n",
    "                  kernel_size = (5,5),\n",
    "                  input_shape = (width, height, channels),\n",
    "                  activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add max pooling layer with a 2x2 layer window\n",
    "network.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dropout layer\n",
    "network.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a layer to flatten the input\n",
    "network.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add fully connected layer of 128 units with a ReLU activation function\n",
    "network.add(Dense(10, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add another dropout layer\n",
    "network.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the sequential neural network\n",
    "network.compile(loss = \"categorical_crossentropy\",\n",
    "               optimizer = \"rmsprop\",\n",
    "               metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c328f88970>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the sequential neural network\n",
    "network.fit(features_train,\n",
    "           target_train,\n",
    "           epochs = 2,\n",
    "           verbose = 0,\n",
    "           batch_size = 1000,\n",
    "           validation_data = (features_test, target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 3s - loss: nan - accuracy: 0.0980\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(features_test, target_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09799999743700027\n"
     ]
    }
   ],
   "source": [
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
